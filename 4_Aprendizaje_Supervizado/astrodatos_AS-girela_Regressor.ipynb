{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapeando el Universo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje Supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación del tipo morfológico de galaxias\n",
    "\n",
    "  * Implementar los modelos random forest y redes neuronales para clasificar las galaxias en tipo Elípticas y Espirales e Irregulares\n",
    "  \n",
    "    + Utilizar al menos dos subconjuntos diferentes de variables (uno puede ser el mejor conjunto que les resultó del práctico anterior)\n",
    "    + Realizar una búsqueda en grilla de los mejores parámetros de los modelos empleandos.\n",
    "    + Comparar la performance con los modelos de perceptrón, regresión logística, vecinos más cercanos o el que hayan utilizado en el práctico anterior.\n",
    "  \n",
    "### Determinación del _redshift_ de las galaxias\n",
    "\n",
    "  * Implementar los modelos de random forest, multi-layer perceptron y/o stochastic gradient descent para determinar el _redshift_ de las galaxias a partir de las propiedades fotométricas.\n",
    "  \n",
    "    + Utilizar al menos dos subconjuntos diferentes de variables (uno puede ser el mejor conjunto que les resultó del práctico anterior)\n",
    "    + Determinar cuales son los parámetros de los algoritmos más importantes y realizar una búsqueda en grilla de los mejores parámetros de los modelos empleandos.\n",
    "    + Elijan un métrica para evaluar el rendimiento de los métodos.\n",
    "    \n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es una manera, pueden utilizar las que más les convenga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"~/DiploDatos_clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['modelColor_ug'] = df['modelMag_u'] - df['modelMag_g']\n",
    "df['modelColor_gr'] = df['modelMag_g'] - df['modelMag_r']\n",
    "df['modelColor_ri'] = df['modelMag_r'] - df['modelMag_i']\n",
    "df['modelColor_iz'] = df['modelMag_i'] - df['modelMag_z']\n",
    "df['petroColor_ug'] = df['petroMag_u'] - df['petroMag_g']\n",
    "df['petroColor_gr'] = df['petroMag_g'] - df['petroMag_r']\n",
    "df['petroColor_ri'] = df['petroMag_r'] - df['petroMag_i']\n",
    "df['petroColor_iz'] = df['petroMag_i'] - df['petroMag_z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniendo dataframes\n",
    "\n",
    "Vamos a ir un poco más allá y vamos a unir la tabla anterior con otra donde para algunas de las galaxias la gente a votado si se corresponde con una galaxia espiral, eliptica o irregular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '~/DiploDatos_Zoo.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoo = pd.read_csv(filename,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.join(zoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(585382, 83)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.spiral = data.spiral.fillna(0)\n",
    "data.elliptical = data.elliptical.fillna(0)\n",
    "data.uncertain = data.uncertain.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.spiral == 0) & (data.elliptical == 0) & (data.uncertain == 0), 'uncertain'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación del tipo morfológico de galaxias\n",
    "\n",
    "  * Implementar los modelos random forest y redes neuronales para clasificar las galaxias en tipo Elípticas y Espirales e Irregulares\n",
    "  \n",
    "    + Utilizar al menos dos subconjuntos diferentes de variables (uno puede ser el mejor conjunto que les resultó del práctico anterior)\n",
    "    + Realizar una búsqueda en grilla de los mejores parámetros de los modelos empleandos.\n",
    "    + Comparar la performance con los modelos de perceptrón, regresión logística, vecinos más cercanos o el que hayan utilizado en el práctico anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de los resultados del práctico anterior..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset1 = [col for col in data.columns if col.startswith(\"model\")] + [col for col in data.columns if col.startswith(\"deVRad\")]\n",
    "subset3 = [col for col in data.columns if col.startswith(\"petro\")]\n",
    "subsets = [subset1, subset3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que establecer los labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: \n",
      " 0 => Uncertain\n",
      " 1 => Spiral\n",
      " 2 => Elliptical\n"
     ]
    }
   ],
   "source": [
    "data.labels = data.spiral\n",
    "data.labels.loc[(data.elliptical == 1)] = 2\n",
    "data.labels.loc[(data.uncertain == 1)] = 0\n",
    "print(\"Labels: \\n 0 => Uncertain\\n 1 => Spiral\\n 2 => Elliptical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 585382 entries, 957075158303008768 to 957064987820451840\n",
      "Data columns (total 83 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   z                               585382 non-null  float64\n",
      " 1   subClass_AGN                    585382 non-null  int64  \n",
      " 2   subClass_AGN BROADLINE          585382 non-null  int64  \n",
      " 3   subClass_BROADLINE              585382 non-null  int64  \n",
      " 4   subClass_STARBURST              585382 non-null  int64  \n",
      " 5   subClass_STARBURST BROADLINE    585382 non-null  int64  \n",
      " 6   subClass_STARFORMING            585382 non-null  int64  \n",
      " 7   subClass_STARFORMING BROADLINE  585382 non-null  int64  \n",
      " 8   subClass_UNKNOWN                585382 non-null  int64  \n",
      " 9   velDisp                         585382 non-null  float64\n",
      " 10  ra                              585382 non-null  float64\n",
      " 11  dec                             585382 non-null  float64\n",
      " 12  modelMag_u                      585382 non-null  float64\n",
      " 13  modelMag_g                      585382 non-null  float64\n",
      " 14  modelMag_r                      585382 non-null  float64\n",
      " 15  modelMag_i                      585382 non-null  float64\n",
      " 16  modelMag_z                      585382 non-null  float64\n",
      " 17  petroMag_u                      585382 non-null  float64\n",
      " 18  petroMag_g                      585382 non-null  float64\n",
      " 19  petroMag_r                      585382 non-null  float64\n",
      " 20  petroMag_i                      585382 non-null  float64\n",
      " 21  petroMag_z                      585382 non-null  float64\n",
      " 22  petroRad_u                      585382 non-null  float64\n",
      " 23  petroRad_g                      585382 non-null  float64\n",
      " 24  petroRad_r                      585382 non-null  float64\n",
      " 25  petroRad_i                      585382 non-null  float64\n",
      " 26  petroRad_z                      585382 non-null  float64\n",
      " 27  petroR50_u                      585382 non-null  float64\n",
      " 28  petroR50_g                      585382 non-null  float64\n",
      " 29  petroR50_r                      585382 non-null  float64\n",
      " 30  petroR50_i                      585382 non-null  float64\n",
      " 31  petroR50_z                      585382 non-null  float64\n",
      " 32  petroR90_u                      585382 non-null  float64\n",
      " 33  petroR90_g                      585382 non-null  float64\n",
      " 34  petroR90_r                      585382 non-null  float64\n",
      " 35  petroR90_i                      585382 non-null  float64\n",
      " 36  petroR90_z                      585382 non-null  float64\n",
      " 37  deVRad_u                        585382 non-null  float64\n",
      " 38  deVRad_g                        585382 non-null  float64\n",
      " 39  deVRad_r                        585382 non-null  float64\n",
      " 40  deVRad_i                        585382 non-null  float64\n",
      " 41  deVRad_z                        585382 non-null  float64\n",
      " 42  deVAB_u                         585382 non-null  float64\n",
      " 43  deVAB_g                         585382 non-null  float64\n",
      " 44  deVAB_r                         585382 non-null  float64\n",
      " 45  deVAB_i                         585382 non-null  float64\n",
      " 46  deVAB_z                         585382 non-null  float64\n",
      " 47  deVPhi_u                        585382 non-null  float64\n",
      " 48  deVPhi_g                        585382 non-null  float64\n",
      " 49  deVPhi_r                        585382 non-null  float64\n",
      " 50  deVPhi_i                        585382 non-null  float64\n",
      " 51  deVPhi_z                        585382 non-null  float64\n",
      " 52  expRad_u                        585382 non-null  float64\n",
      " 53  expRad_g                        585382 non-null  float64\n",
      " 54  expRad_r                        585382 non-null  float64\n",
      " 55  expRad_i                        585382 non-null  float64\n",
      " 56  expRad_z                        585382 non-null  float64\n",
      " 57  expAB_u                         585382 non-null  float64\n",
      " 58  expAB_g                         585382 non-null  float64\n",
      " 59  expAB_r                         585382 non-null  float64\n",
      " 60  expAB_i                         585382 non-null  float64\n",
      " 61  expAB_z                         585382 non-null  float64\n",
      " 62  expPhi_u                        585382 non-null  float64\n",
      " 63  expPhi_g                        585382 non-null  float64\n",
      " 64  expPhi_r                        585382 non-null  float64\n",
      " 65  expPhi_i                        585382 non-null  float64\n",
      " 66  expPhi_z                        585382 non-null  float64\n",
      " 67  extinction_u                    585382 non-null  float64\n",
      " 68  extinction_g                    585382 non-null  float64\n",
      " 69  extinction_r                    585382 non-null  float64\n",
      " 70  extinction_i                    585382 non-null  float64\n",
      " 71  extinction_z                    585382 non-null  float64\n",
      " 72  modelColor_ug                   585382 non-null  float64\n",
      " 73  modelColor_gr                   585382 non-null  float64\n",
      " 74  modelColor_ri                   585382 non-null  float64\n",
      " 75  modelColor_iz                   585382 non-null  float64\n",
      " 76  petroColor_ug                   585382 non-null  float64\n",
      " 77  petroColor_gr                   585382 non-null  float64\n",
      " 78  petroColor_ri                   585382 non-null  float64\n",
      " 79  petroColor_iz                   585382 non-null  float64\n",
      " 80  spiral                          585382 non-null  float64\n",
      " 81  elliptical                      585382 non-null  float64\n",
      " 82  uncertain                       585382 non-null  float64\n",
      "dtypes: float64(75), int64(8)\n",
      "memory usage: 395.2 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"reducing.py\n",
    "Author: Kirgsn, 2018\n",
    "\n",
    "Use like this:\n",
    ">>> import reducing\n",
    ">>> df = reducing.Reducer().reduce(df)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "from fastprogress import master_bar, progress_bar\n",
    "\n",
    "__all__ = ['Reducer']\n",
    "\n",
    "def measure_time_mem(func):\n",
    "    def wrapped_reduce(self, df, *args, **kwargs):\n",
    "        # pre\n",
    "        mem_usage_orig = df.memory_usage().sum() / self.memory_scale_factor\n",
    "        start_time = time.time()\n",
    "        # exec\n",
    "        ret = func(self, df, *args, **kwargs)\n",
    "        # post\n",
    "        mem_usage_new = ret.memory_usage().sum() / self.memory_scale_factor\n",
    "        end_time = time.time()\n",
    "        print(f'reduced df from {mem_usage_orig:.4f} MB '\n",
    "              f'to {mem_usage_new:.4f} MB '\n",
    "              f'in {(end_time - start_time):.2f} seconds')\n",
    "        gc.collect()\n",
    "        return ret\n",
    "    return wrapped_reduce\n",
    "\n",
    "class Reducer:\n",
    "    \"\"\"\n",
    "    Class that takes a dict of increasingly big numpy datatypes to transform\n",
    "    the data of a pandas dataframe into, in order to save memory usage.\n",
    "    \"\"\"\n",
    "    memory_scale_factor = 1024**2  # memory in MB\n",
    "\n",
    "    def __init__(self, conv_table=None, use_categoricals=True, n_jobs=-1):\n",
    "        \"\"\"\n",
    "        :param conv_table: dict with np.dtypes-strings as keys\n",
    "        :param use_categoricals: Whether the new pandas dtype \"Categoricals\"\n",
    "                shall be used\n",
    "        :param n_jobs: Parallelization rate\n",
    "        \"\"\"\n",
    "\n",
    "        self.conversion_table = \\\n",
    "            conv_table or {'int': [np.int8, np.int16, np.int32, np.int64],\n",
    "                           'uint': [np.uint8, np.uint16, np.uint32, np.uint64],\n",
    "                           'float': [np.float32, ]}\n",
    "        self.null_int = {   np.int8:  pd.Int8Dtype,\n",
    "                            np.int16: pd.Int16Dtype,\n",
    "                            np.int32: pd.Int32Dtype,\n",
    "                            np.int64: pd.Int64Dtype,\n",
    "                            np.uint8: pd.UInt8Dtype,\n",
    "                            np.uint16:pd.UInt16Dtype,\n",
    "                            np.uint32:pd.UInt32Dtype,\n",
    "                            np.uint64:pd.UInt64Dtype}\n",
    "        \n",
    "        self.use_categoricals = use_categoricals\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "    def _type_candidates(self, k):\n",
    "        for c in self.conversion_table[k]:\n",
    "            i = np.iinfo(c) if 'int' in k else np.finfo(c)\n",
    "            yield c, i\n",
    "\n",
    "    @measure_time_mem\n",
    "    def reduce(self, df, verbose=False):\n",
    "        \"\"\"Takes a dataframe and returns it with all data transformed to the\n",
    "        smallest necessary types.\n",
    "\n",
    "        :param df: pandas dataframe\n",
    "        :param verbose: If True, outputs more information\n",
    "        :return: pandas dataframe with reduced data types\n",
    "        \"\"\"\n",
    "        ret_list = Parallel(n_jobs=self.n_jobs, max_nbytes=None)(progress_bar(list(delayed(self._reduce)\n",
    "                                                (df[c], c, verbose) for c in\n",
    "                                                df.columns)))\n",
    "\n",
    "        del df\n",
    "        gc.collect()\n",
    "        return pd.concat(ret_list, axis=1)\n",
    "    \n",
    "    def _reduce(self, s, colname, verbose):\n",
    "        try:\n",
    "            isnull = False\n",
    "            # skip NaNs\n",
    "            if s.isnull().any():\n",
    "                isnull = True\n",
    "            # detect kind of type\n",
    "            coltype = s.dtype\n",
    "            if np.issubdtype(coltype, np.integer):\n",
    "                conv_key = 'int' if s.min() < 0 else 'uint'\n",
    "            elif np.issubdtype(coltype, np.floating):\n",
    "                conv_key = 'float'\n",
    "                asint = s.fillna(0).astype(np.int64)\n",
    "                result = (s - asint)\n",
    "                result = np.abs(result.sum())\n",
    "                if result < 0.01:\n",
    "                    conv_key = 'int' if s.min() < 0 else 'uint'\n",
    "            else:\n",
    "                if isinstance(coltype, object) and self.use_categoricals:\n",
    "                    # check for all-strings series\n",
    "                    if s.apply(lambda x: isinstance(x, str)).all():\n",
    "                        if verbose: print(f'convert {colname} to categorical')\n",
    "                        return s.astype('category')\n",
    "                if verbose: print(f'{colname} is {coltype} - Skip..')\n",
    "                return s\n",
    "            # find right candidate\n",
    "            for cand, cand_info in self._type_candidates(conv_key):\n",
    "                if s.max() <= cand_info.max and s.min() >= cand_info.min:\n",
    "                    if verbose: print(f'convert {colname} to {cand}')\n",
    "                    if isnull:\n",
    "                        return s.astype(self.null_int[cand]())\n",
    "                    else:\n",
    "                        return s.astype(cand)\n",
    "\n",
    "            # reaching this code is bad. Probably there are inf, or other high numbs\n",
    "            print(f\"WARNING: {colname} doesn't fit the grid with \\nmax: {s.max()} \"\n",
    "                f\"and \\nmin: {s.min()}\")\n",
    "            print('Dropping it..')\n",
    "        except Exception as ex:\n",
    "            print(f'Exception for {colname}: {ex}')\n",
    "            return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='83' class='' max='83' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [83/83 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduced df from 395.1533 MB to 171.3870 MB in 10.55 seconds\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 585382 entries, 957075158303008768 to 957064987820451840\n",
      "Data columns (total 83 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   z                               585382 non-null  float32\n",
      " 1   subClass_AGN                    585382 non-null  uint8  \n",
      " 2   subClass_AGN BROADLINE          585382 non-null  uint8  \n",
      " 3   subClass_BROADLINE              585382 non-null  uint8  \n",
      " 4   subClass_STARBURST              585382 non-null  uint8  \n",
      " 5   subClass_STARBURST BROADLINE    585382 non-null  uint8  \n",
      " 6   subClass_STARFORMING            585382 non-null  uint8  \n",
      " 7   subClass_STARFORMING BROADLINE  585382 non-null  uint8  \n",
      " 8   subClass_UNKNOWN                585382 non-null  uint8  \n",
      " 9   velDisp                         585382 non-null  float32\n",
      " 10  ra                              585382 non-null  float32\n",
      " 11  dec                             585382 non-null  float32\n",
      " 12  modelMag_u                      585382 non-null  float32\n",
      " 13  modelMag_g                      585382 non-null  float32\n",
      " 14  modelMag_r                      585382 non-null  float32\n",
      " 15  modelMag_i                      585382 non-null  float32\n",
      " 16  modelMag_z                      585382 non-null  float32\n",
      " 17  petroMag_u                      585382 non-null  float32\n",
      " 18  petroMag_g                      585382 non-null  float32\n",
      " 19  petroMag_r                      585382 non-null  float32\n",
      " 20  petroMag_i                      585382 non-null  float32\n",
      " 21  petroMag_z                      585382 non-null  float32\n",
      " 22  petroRad_u                      585382 non-null  float32\n",
      " 23  petroRad_g                      585382 non-null  float32\n",
      " 24  petroRad_r                      585382 non-null  float32\n",
      " 25  petroRad_i                      585382 non-null  float32\n",
      " 26  petroRad_z                      585382 non-null  float32\n",
      " 27  petroR50_u                      585382 non-null  float32\n",
      " 28  petroR50_g                      585382 non-null  float32\n",
      " 29  petroR50_r                      585382 non-null  float32\n",
      " 30  petroR50_i                      585382 non-null  float32\n",
      " 31  petroR50_z                      585382 non-null  float32\n",
      " 32  petroR90_u                      585382 non-null  float32\n",
      " 33  petroR90_g                      585382 non-null  float32\n",
      " 34  petroR90_r                      585382 non-null  float32\n",
      " 35  petroR90_i                      585382 non-null  float32\n",
      " 36  petroR90_z                      585382 non-null  float32\n",
      " 37  deVRad_u                        585382 non-null  float32\n",
      " 38  deVRad_g                        585382 non-null  float32\n",
      " 39  deVRad_r                        585382 non-null  float32\n",
      " 40  deVRad_i                        585382 non-null  float32\n",
      " 41  deVRad_z                        585382 non-null  float32\n",
      " 42  deVAB_u                         585382 non-null  float32\n",
      " 43  deVAB_g                         585382 non-null  float32\n",
      " 44  deVAB_r                         585382 non-null  float32\n",
      " 45  deVAB_i                         585382 non-null  float32\n",
      " 46  deVAB_z                         585382 non-null  float32\n",
      " 47  deVPhi_u                        585382 non-null  float32\n",
      " 48  deVPhi_g                        585382 non-null  float32\n",
      " 49  deVPhi_r                        585382 non-null  float32\n",
      " 50  deVPhi_i                        585382 non-null  float32\n",
      " 51  deVPhi_z                        585382 non-null  float32\n",
      " 52  expRad_u                        585382 non-null  float32\n",
      " 53  expRad_g                        585382 non-null  float32\n",
      " 54  expRad_r                        585382 non-null  float32\n",
      " 55  expRad_i                        585382 non-null  float32\n",
      " 56  expRad_z                        585382 non-null  float32\n",
      " 57  expAB_u                         585382 non-null  float32\n",
      " 58  expAB_g                         585382 non-null  float32\n",
      " 59  expAB_r                         585382 non-null  float32\n",
      " 60  expAB_i                         585382 non-null  float32\n",
      " 61  expAB_z                         585382 non-null  float32\n",
      " 62  expPhi_u                        585382 non-null  float32\n",
      " 63  expPhi_g                        585382 non-null  float32\n",
      " 64  expPhi_r                        585382 non-null  float32\n",
      " 65  expPhi_i                        585382 non-null  float32\n",
      " 66  expPhi_z                        585382 non-null  float32\n",
      " 67  extinction_u                    585382 non-null  float32\n",
      " 68  extinction_g                    585382 non-null  float32\n",
      " 69  extinction_r                    585382 non-null  float32\n",
      " 70  extinction_i                    585382 non-null  float32\n",
      " 71  extinction_z                    585382 non-null  float32\n",
      " 72  modelColor_ug                   585382 non-null  float32\n",
      " 73  modelColor_gr                   585382 non-null  float32\n",
      " 74  modelColor_ri                   585382 non-null  float32\n",
      " 75  modelColor_iz                   585382 non-null  float32\n",
      " 76  petroColor_ug                   585382 non-null  float32\n",
      " 77  petroColor_gr                   585382 non-null  float32\n",
      " 78  petroColor_ri                   585382 non-null  float32\n",
      " 79  petroColor_iz                   585382 non-null  float32\n",
      " 80  spiral                          585382 non-null  uint8  \n",
      " 81  elliptical                      585382 non-null  uint8  \n",
      " 82  uncertain                       585382 non-null  uint8  \n",
      "dtypes: float32(72), uint8(11)\n",
      "memory usage: 171.4 MB\n"
     ]
    }
   ],
   "source": [
    "data = Reducer().reduce(data)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "### Determinación del _redshift_ de las galaxias\n",
    "\n",
    "  * Implementar los modelos de random forest, multi-layer perceptron y/o stochastic gradient descent para determinar el _redshift_ de las galaxias a partir de las propiedades fotométricas.\n",
    "  \n",
    "    + Utilizar al menos dos subconjuntos diferentes de variables (uno puede ser el mejor conjunto que les resultó del práctico anterior)\n",
    "    + Determinar cuales son los parámetros de los algoritmos más importantes y realizar una búsqueda en grilla de los mejores parámetros de los modelos empleandos.\n",
    "    + Elijan un métrica para evaluar el rendimiento de los métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajamos con las magnitudes Model que han dado mejores resultados en el práctico anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\" : [200,100,50,10],\n",
    "    \"max_depth\" : [6,10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_cv(model,X,y):\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=-1)\n",
    "    grid.fit(X,y)\n",
    "    best_model = grid.best_estimator_\n",
    "    return best_model\n",
    "def split(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "def random_forest(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"Train MSE Error\")\n",
    "    print(mean_squared_error(y_train,y_train_pred))\n",
    "    print(\"Test MSE Error\")\n",
    "    print(mean_squared_error(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor\n",
      "RandomForestRegressor(max_depth=20, n_estimators=200, n_jobs=-1, random_state=0)\n",
      "----------\n",
      "_____________________\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "X = data[subset1]\n",
    "y = data.z\n",
    "print(\"Random Forest Regressor\")\n",
    "model = grid_cv(model, X, y)\n",
    "print(model)\n",
    "print(\"----------\")\n",
    "name = \"randomforestCV_\" + \"modelMag\" + \".pkl\"\n",
    "joblib.dump(model, name)\n",
    "print(\"_____________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE Error\n",
      "0.00015687338982727005\n",
      "Test MSE Error\n",
      "0.0005497582982857604\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split(X,y)\n",
    "random_forest(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastics Gradient Descent Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"loss\" : [\"squared_loss\", \"huber\"],\n",
    "    \"penalty\" : [\"l1\",\"l2\"],\n",
    "    \"alpha\" : [1000,200,100,50,0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_cv(model,X,y):\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, cv=5, n_jobs=-1)\n",
    "    grid.fit(X,y)\n",
    "    best_model = grid.best_estimator_\n",
    "    return best_model\n",
    "def split(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "def sgdr(model,X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"Train MSE Error\")\n",
    "    print(mean_squared_error(y_train,y_train_pred))\n",
    "    print(\"Test MSE Error\")\n",
    "    print(mean_squared_error(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor\n",
      "SGDRegressor(alpha=0, loss='huber', penalty='l1', random_state=0)\n",
      "----------\n",
      "_____________________\n",
      "_____________________\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "X = data[subset1]\n",
    "y = data.z\n",
    "print(\"SGDRegressor\")\n",
    "model = grid_cv(model, X, y)\n",
    "print(model)\n",
    "print(\"----------\")\n",
    "name = \"SGDRCV_\" + \"modelMag\" + \".pkl\"\n",
    "joblib.dump(model, name)\n",
    "print(\"_____________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE Error\n",
      "0.0017920295072500522\n",
      "Test MSE Error\n",
      "0.0017992826721478844\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split(X,y)\n",
    "sgdr(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo es un Random Forest Regressor para las magnitudes Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
